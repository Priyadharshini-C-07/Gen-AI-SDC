import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
import numpy as np

# Sample email dataset (messages and labels)
emails = [
    "Get a free iPhone now", "Important meeting at 10 AM", 
    "Claim your reward now!", "Let's catch up later", 
    "Exclusive offer for you", "See you at the party tonight"
]
labels = [1, 0, 1, 0, 1, 0]  # 1 for spam, 0 for ham (not spam)

# Tokenization
tokenizer = Tokenizer()
tokenizer.fit_on_texts(emails)
X = tokenizer.texts_to_sequences(emails)
X = pad_sequences(X)

# Convert labels to numpy array
y = np.array(labels)

# Build a simple LSTM neural network for spam detection
model = Sequential([
    Embedding(input_dim=5000, output_dim=128, input_length=X.shape[1]),
    SpatialDropout1D(0.2),
    LSTM(100, dropout=0.2, recurrent_dropout=0.2),
    Dense(1, activation='sigmoid')
])

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model
model.fit(X, y, epochs=5, batch_size=32)

# Get user input for spam detection
test_email = input("Enter an email to check (spam or ham): ")
test_seq = tokenizer.texts_to_sequences([test_email])
test_seq = pad_sequences(test_seq, maxlen=X.shape[1])

prediction = model.predict(test_seq)
print(f"Prediction: {'Spam' if prediction > 0.5 else 'Ham'}")
